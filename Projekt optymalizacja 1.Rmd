---
title: "Projekt - Optymalizacja nieliniowa"
subtitle: "Optymalizacja jednowymiarowa"
author: 
  - "Flip Walkowicz"
  - "Numer indeksu: 169860"
  - "Grupa laboratoryjna: 5"
  - "\n"
  - "Krystian Urban"
  - "Numer indeksu: 169857"
  - "Grupa laboratoryjna: 5"
date: "`r Sys.Date()`"
header-includes: 
  - \renewcommand{\and}{\\}
output:
  pdf_document:
    fig_caption: true
    number_sections: true
  html_document: default
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{=tex}
\newpage
\renewcommand*\contentsname{Spis treści}
\tableofcontents
\newpage
```
# Wstęp oraz opis celu projektu

<!-- ## Wstęp teoretyczny -->

## Cele projekt

Celem ćwiczenia jest zapoznanie się z gradientowymi oraz bezgradientowymi metodami optymalizacji jednowymiarowej poprzez ich implementację i zastosowanie do wyznaczenia minimów i maksimów podanej funkcji.

## Teoria

\newpage

# Wizualizacja funkcji celu

W tym pukcie naszego projektu zwizualizujemy naszą funkcję celu którą będziemy badać. $$f(x) = \sin(\frac{x}{10}) \times e^{-(\frac{x}{10} + \pi)^2} - \cos(\frac{x}{10}) \times e^{-(\frac{x}{10} - 2\pi)^2} + 0.003( \frac{x}{10})^2$$

```{r comment=NA, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# bibliotego do rysowania wykresów
library(ggplot2)

# definicja funkcji celu
funkcja_celu <- function(x) {
  return(sin(x/10)*exp(-(x/10+pi)^2) - cos(x/10)*exp(-(x/10-2*pi)^2) + 0.003*(x/10)^2)
}

# generowanie x
x_values <- seq(-100, 100, length.out = 1000)
# generowanie y
y_values <- funkcja_celu(x_values)

# stworzenie ramki danych
data <- data.frame(x = x_values, y = y_values)

# wizualizacja danych
ggplot(data, aes(x = x, y = y)) +
  geom_line() +
  labs(x = 'X', y = 'Y', title = 'Funkcja celu') 
```

# Dwupunktowa metoda ekspansji Boxa-Daviesa-Swanna

## Opis działania algorytmu
Jest to metoda zaproponowana i opracowana przez Boxa, Daviesa oraz Swanna. Podobna do metody ekspansji z modyfikacją dla punktu początkowego różnego od zera.
Startujemy z dowolnego punktu a współczynnik ekspansni jest stale równy 2. Znajdujemy przedział w którym znajduje się minimum funkcji więc testujemy w tym algorytmie 
wartości funkcji na lewo( lewy koniec przedziału) jak i na prawo( prawy koniec przedziału).
  
  Poszukiwanie zaczynamy od sprawdzenia wartości funkcji na lewo/prawo od punktu startowego:
  $$x_a{i+1} = x_0 - 2^{i}\delta$$
  $$x_b{i+1} = x_0 + 2^{i}\delta$$
Poszukiwania prowadzimy tak długo aż funkcja nie zacznie nam rosnąć(w obu przypadkach) czyli:
$$f(x_{i+1}) > f (x_i)$$

## Implementacja w kodzie

```{r comment=NA, tidy=TRUE, tidy.opts=list(width.cutoff=80)}
BDS <- function(f, x0, step){
  iterator <- 0
  found_a <- FALSE
  found_b <- FALSE
  a <- 0
  b <- 0
  while(TRUE){
    next_x_a <- x0 - 2 ** iterator * step
    next_x_b <- x0 + 2 ** iterator * step
    if(f(next_x_a) >= f(x0) & found_a == FALSE){
      a <- next_x_a
      found_a <- TRUE
    }
    if(f(next_x_b) >= f(x0) & found_b == FALSE){
      b <- next_x_b
      found_b <- TRUE
    }
    if(found_a & found_b){
      return(c(a, b))
    }
    iterator <- iterator + 1
  }
}
BDS(funkcja_celu, 50, 1/100)
```

\newpage

# Interpolacji Lagrange'a

## Opis działania kodu

  Metda działania algorytmu opartego na interpolacji Lagrange'a polega na wyszukaniu minimum/maxiumum na danym przedziale $[a, b]$. 
Algorytm w każdym kroku wyznacza trzy punkty, odpowiednio:

- a - początek przedziału
- c - środek przedziału
- b - koniec przedziału

Następnie przez te punkty zostaje poprowadzony wielomian drugiego stopnia wyznaczony właśnie na podstawie wzoru interpolacyjnego Lagrange'a.
Wyznaczone minimum na przedziale $[a, b]$(w każdym kroku nowe) pozwala nam zawęzić przedział poszukiwań.
Minimum wyznaczamy następującym wzorem:
$$d = \frac{1}{2} \times \frac{f(a)(c^2 - b^2) + f(c)(b^2 - a^2) + f(b)(a^2  - c^2)}{f(a)(c - b) + f(c)(b - a) + f(b)(a - c)}$$
Następnie sprawdzamy warunki na których podstawie wyznaczamy nowy przedział:

- $a < d < c \space \land \space f(d) < f(c)$
- $a < d < c \space \land \space f(d) \geqslant f(c)$
- $c < d < b \space \land \space f(d) < f(c)$
- $c < d < b \space \land \space f(d) \geqslant f(c)$

Koniec naszego algorytmu wyznacza długość przedziału który jest mniejszy od dokładności $\epsilon$.

  Opis algotytmu krok po kroku:

- Podaj funkcję, przedział oraz dokładność
- Pierwsze wyznaczenie punktów a(początek przedziału), c(środek przedziału), b(koniec przedziału)
- Powtarzanie w pętli while do póki długość przedziału jest mniejsza od dokładności:
  + wyznaczenie minimum z wzoru interpolacyjnego Lagrange'a
  + sprawdzenie warunku koniecznego
  + wyznaczenie nowego przedziału
  
Różnica w kodzie pomiędzy wyszukiwaniem minimum lokalnego a maksimum lokalnego polega na

## Implementacja w kodzie
```{r comment=NA, tidy=TRUE, tidy.opts=list(width.cutoff=80)}
lagrange_interpolation <- function(f, a, c, b) {
  return(1/2 *(f(a)*(c^2-b^2) + f(c)*(b^2-a^2) + f(b)*(a^2-c^2))/(f(a)*(c-b) + f(c)*(b-a) + f(b)*(a-c)))
}

cut_solution_interval <- function(f, a, c, b, d) {
  if(a < d & d < c & f(d) < f(c)){
    return(c(a, d, c))
  }
  if(a < d & d < c & f(d) >= f(c)){
    return(c(d, c, b))
  }
  if(c < d & d < b & f(d) < f(c)){
    return(c(c, d, b))
  }
  if(c< d & d < b & f(d) >= f(c)){
    return(c(a, c, d))
  }
}

lagrange_min <- function(f, start_point, epsilon) {
  interval <- BDS(f, start_point, 1/100)
  a <- interval[1]
  c <- (interval[1] + interval[2]) / 2
  b <- interval[2]
  d <- 0

  if (a >= c || c >= b || a >= b) {
    return('Źle podany przedział')
  }

  while (b - a > epsilon || b - a == 0) {
    d <- lagrange_interpolation(f, a, c, b)

    if (d > a & d < b & d != c) {
      new_interval <- cut_solution_interval(f, a, c, b, d)
      a <- new_interval[1]
      c <- new_interval[2]
      b <- new_interval[3]
    } else {
      return('Nie jest zbieżny')
    }
  }

  return(c(a, b))
}

result <- lagrange_min(funkcja_celu, 10, 1/1000)
print(result)
```

## Badanie wydajności metody
```{r}
intervals <- sample(-100:100, 100, replace = TRUE)
results_a <- c()
results_b <- c()
for (i in 1:(length(intervals)-1)) {
    results <- lagrange_min(funkcja_celu, intervals[i], 1/1000)
    results_a <- c(results_a, results[1])
    results_b <- c(results_b, results[2])
}
result_matrix <- cbind(results_a, results_b)
print(head(result_matrix, 3))

library(openxlsx)
write.xlsx(as.data.frame(result_matrix) , './pomiary.xlsx')
```

# Metoda Newtona-Armijo

## Warunek Armijo

```{r}
armijoCondition <- function(func, x0, d, alpha){
  if(0 > alpha || alpha > 1){
    stop("Alfa nie jest z przedzialu [0,1]")
  }
  derivative <- Deriv(func)
  function_calls <<- function_calls + 2
  return(
    func(x0 + d) <= func(x0) + (d * alpha * derivative(x0))
  )
}
```

## Znajdowanie prawidłowej wielkości kroku

```{r}

determineStepSize <- function(funcDeriv, x){
  return(
    -1 * (funcDeriv[[1]](x)/funcDeriv[[2]](x))
  )
}

tuneStepSize <- function(func, x0, d, alpha, rho){
  while (armijoCondition(func, x0, d, alpha) == FALSE) {
    d <- d * rho
  }
  return(d)
}
```

## Pobieranie drugiej pochodnej

```{r}
getDerivs <- function(func){
  firstDerivative <- Deriv(func)
  secondDerivative <- Deriv(firstDerivative)
  return(c(
    firstDerivative, secondDerivative
  ))
}
```


## Badanie kierunku spadku wartości funkcji

```{r}

functionValueDecreaseDirection <- function(functionDeriv, x){
  if(functionDeriv[1][[1]](x) < 0){
    return(-1)
  }
  return(1)
}

```



## Metoda Newtona-Armijo

```{r}
newtonArmijo <- function(func, x, alpha, rho, tolerance){
  funcDerivative <- getDerivs(func)
  x.new <- x
  iterations <- 0
  repeat{
    iterations <- iterations + 1
    if(funcDerivative[2][[1]](x) >= 0){
      d <- determineStepSize(funcDerivative, x)
    }
    else{
      d <- 1 * functionValueDecreaseDirection(funcDerivative, x)
    }
    d <- tuneStepSize(func, x, d, alpha, rho)
    x.new <- x + d
    if(abs(x.new - x) < tolerance){
      return(c(x.new, func(x.new), function_calls))
    }
    if(x.new < -80 || x.new > 100){
      return(c(NA, NA, function_calls))
    }
    if(iterations == 100){
      return(c(NA, NA, 0))
    }
    x <- x.new
    y <- func(x)
  }
}

```


## Wykorzystane biblioteki

-   ggplot2
-   formatR
-   openxlsx
-   Deriv
